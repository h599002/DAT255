{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optimisers \n",
    "\n",
    "This notebook experiments with the different optimisation algorithms implemented in Keras, and the effect of their various setting.\n",
    "\n",
    "For visualisation purposes we will not train any networks at all this time, but look at some classic two-dimensial numerical optimisation problems. This means we cannot use Keras' `model.fit()` function, but we will instead write an optimisation loop ourselves. This has the added benefit of showing us exactly the steps involved in doing gradient descent. \n",
    "\n",
    "The different optimisers we will look at are described in the Keras [documentation](https://keras.io/api/optimizers/). They are all based on computing gradients and stepping in the downwards direction, but apply some tweaks in how the next step is computed. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The regular imports:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import keras \n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optimisation problems\n",
    "\n",
    "When we say optimisation problems, technically we mean _minimisation_ -- since our task in deep learning is to find the smallest possible prediction error. \n",
    "\n",
    "Here we define two diffent functions where the minimum point is somewhat difficult to find. There exists more difficult problems too, just have a look at this [Wikipedia page](https://en.wikipedia.org/wiki/Test_functions_for_optimization) for a list of other ones. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rosenbrock function\n",
    "def rosen(x, y):\n",
    "\treturn (1-x)**2 + 100*(y - x**2)**2\n",
    "\n",
    "# Beale function\n",
    "def beale(x, y):\n",
    "\treturn (1.5 - x + x*y)**2 + (2.25 - x + x*y**2)**2 + (2.625 - x - x*y**3)**2\n",
    "\n",
    "\n",
    "# Some reasonable bounds and starting points for the functions above\n",
    "settings_rosen = {\n",
    "\t'xmin': -2,\n",
    "\t'xmax': 2,\n",
    "\t'ymin': -2,\n",
    "\t'ymax': 2,\n",
    "\t'xstart': 0,\n",
    "\t'ystart': 0,\n",
    "\t'xsolution': 1,\n",
    "\t'ysolution': 1\n",
    "}\n",
    "settings_beale = {\n",
    "\t'xmin': -5,\n",
    "\t'xmax': 5,\n",
    "\t'ymin': -5,\n",
    "\t'ymax': 5,\n",
    "\t'xstart': -2,\n",
    "\t'ystart': -3,\n",
    "\t'xsolution': 3,\n",
    "\t'ysolution': 0.5\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gradient descent optimisation\n",
    "\n",
    "Let's get straight to defining our gradient descent function. \n",
    "\n",
    "We are solving a two-dimensial problem, so we will declare two variables to be optimised, `x` and `y`. We give them some fixed starting values now, but typically one just starts at a random point.\n",
    "\n",
    "When training a neural network, the steps below are identical, the only difference is that we have more parameters. So try to understand what is going on here, before moving on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_optimisation(optimizer, objective, settings, steps=250, verbose=False):\n",
    "\n",
    "    x = tf.Variable(float(settings['xstart']), name='x')\n",
    "    y = tf.Variable(float(settings['ystart']), name='y')\n",
    "\n",
    "    # Log the values after each step\n",
    "    values_per_step = [\n",
    "        [x.numpy(), y.numpy(), objective(x.numpy(), y.numpy())]\n",
    "    ]\n",
    "\n",
    "    for step in range(steps):\n",
    "            \n",
    "        with tf.GradientTape() as tape:\n",
    "            \n",
    "            # Compute the value of our objective function\n",
    "            loss_value = objective(x, y)\n",
    "\n",
    "        # Use the GradientTape to automatically retrieve\n",
    "        # the gradients of the trainable variables with respect to the objective\n",
    "        grads = tape.gradient(loss_value, [x, y])\n",
    "\n",
    "        # Print numbers for this step\n",
    "        if verbose:\n",
    "            print(f'Step {step}: x = {x.numpy()}, y = {y.numpy()}, gradients: {[g.numpy() for g in grads]}')\n",
    "\n",
    "        # Step to the next point by applying the gradients\n",
    "        optimizer.apply_gradients(zip(grads, [x, y]))\n",
    "\n",
    "        # Log values for this step\n",
    "        values_per_step.append([x.numpy(), y.numpy(), objective(x.numpy(), y.numpy())])\n",
    "\n",
    "    # Return the results\n",
    "    return np.array(values_per_step)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To evaluate the results of our experiments, we define a function to show the steps of the gradient descent procedure, along with the solution.\n",
    "\n",
    "In the real world we of course do not know the solution, so this is an idealised exercise :) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_optimisation_result(results, objective, settings):\n",
    "\n",
    "    assert len(results.shape) == 2, '\\'results\\' should have shape (num_steps, 3)'\n",
    "\n",
    "    # Make our grid of x and y values\n",
    "    delta = 0.01\n",
    "    xaxis = np.arange(settings['xmin'], settings['xmax'], delta)\n",
    "    yaxis = np.arange(settings['ymin'], settings['ymax'], delta)\n",
    "    xs, ys = np.meshgrid(xaxis, yaxis)\n",
    "\n",
    "    # Compute the objective function value at all grid points\n",
    "    z = objective(xs, ys)\n",
    "\n",
    "    # Plot contour (surface) of the function\n",
    "    plt.contourf(xs, ys, np.log(z), cmap='viridis_r', levels=100)\n",
    "\n",
    "    # Plot the solution\n",
    "    plt.axvline(settings['xsolution'], c='gray', linewidth=0.5)\n",
    "    plt.axhline(settings['ysolution'], c='gray', linewidth=0.5)\n",
    "    \n",
    "    # Plot the optimiser steps \n",
    "    plt.scatter(results[:,0], results[:,1], c='red')\n",
    "    plt.plot(results[:,0], results[:,1], c='red')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Running gradient descent\n",
    "\n",
    "Now the experimentation starts. First we need to chose the optimisation algorithm (again, the list of different ones is [here](https://keras.io/api/optimizers/)). We start out with the simplest one, stochatic gradient descent (SGD), which steps in the same exact direction as the gradient.\n",
    "\n",
    "We also need to specify how long steps we wish to take, which is given by the `learning_rate` parameter. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = keras.optimizers.SGD(learning_rate=0.001)\n",
    "\n",
    "result = run_optimisation(optimizer, objective=beale, settings=settings_beale, steps=250, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's plot the results and see how well we did:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_optimisation_result(result, objective=beale, settings=settings_beale)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hmm. Maybe not great. \n",
    "\n",
    "We start out with a very long step, so we try again with a smaller learning rate:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = keras.optimizers.SGD(learning_rate=0.0001)\n",
    "\n",
    "# The `verbose` option turns off the output\n",
    "result = run_optimisation(optimizer, objective=beale, settings=settings_beale, steps=250, verbose=False)\n",
    "plot_optimisation_result(result, objective=beale, settings=settings_beale)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Better, but apparently the steps are now so small that finding the minimum takes a lot of steps (and potentionally a lot of time)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style=\"color: red;\">Exercise:<span>\n",
    "\n",
    "Tune the learning rate (and possibly the number of steps) to get closer to the solution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = keras.optimizers.SGD(learning_rate= ??? )\n",
    "\n",
    "result = run_optimisation(optimizer, objective=beale, settings=settings_beale, steps=250, verbose=True)\n",
    "plot_optimisation_result(result, objective=beale, settings=settings_beale)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If crancking up the learning rate, you may run into `NaN` (Not-a-Number) or `inf` (infinity) values. This is basically _game over_ for your optimisation progress. The task is now _numerically unstable_, which is reatively common, but can also be very difficult to fix. \n",
    "\n",
    "It is time to involve more advanced optimisation algorithms. \n",
    "\n",
    "Step one is to add **momentum**, which in Keras is implemented in the `SDG` class."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style=\"color: red;\">Exercise:<span>\n",
    "\n",
    "Play with the `momentum` parameter in the code below to find a good solution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = keras.optimizers.SGD(learning_rate=0.001, momentum=0.2)\n",
    "\n",
    "result = run_optimisation(optimizer, objective=beale, settings=settings_beale, steps=250, verbose=False)\n",
    "plot_optimisation_result(result, objective=beale, settings=settings_beale)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Better optimisers \n",
    "\n",
    "Now for the real experiments: Comparing the modern and preferred optimisers such as Adam, RMSprop, and Nadam.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style=\"color: red;\">Exercise:<span>\n",
    "\n",
    "1) Try out the different possible Keras optimisers.\n",
    "2) Write an improved plotting function that can show multiple results in the same plot. \n",
    "3) Use the improved plotting function to compare different settings like `momentum`, `beta`, etc for most or some of the optimisers.\n",
    "4) (**Optional**:) Implement one of the other optimisation problems listed [here](https://en.wikipedia.org/wiki/Test_functions_for_optimization), and see if the best optimiser for solving the Beal function, is best also for the other problems."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
